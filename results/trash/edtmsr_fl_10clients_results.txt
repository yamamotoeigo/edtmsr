Num clients: 10
Training and evaluation took 2286.37 seconds.
Test Loss: 0.6735
Number of parameters in the model: 739777
Round losses:
Round 1: 1.4601
Round 2: 1.4361
Round 3: 1.0730
Round 4: 0.9127
Round 5: 0.8963
Round 6: 0.9245
Round 7: 0.8356
Round 8: 0.8948
Round 9: 0.8028
Round 10: 0.8396
Round 11: 0.7737
Round 12: 0.9128
Round 13: 0.7640
Round 14: 0.8146
Round 15: 0.7696
Round 16: 0.7514
Round 17: 0.7701
Round 18: 0.7410
Round 19: 0.7516
Round 20: 0.7278
Round 21: 0.7850
Round 22: 0.7242
Round 23: 0.7572
Round 24: 0.7294
Round 25: 0.7170
Round 26: 0.7200
Round 27: 0.7458
Round 28: 0.7061
Round 29: 0.7726
Round 30: 0.7307
Round 31: 0.6963
Round 32: 0.8339
Round 33: 0.6954
Round 34: 0.7630
Round 35: 0.6991
Round 36: 0.7287
Round 37: 0.7047
Round 38: 0.7072
Round 39: 0.6876
Round 40: 0.7373
Round 41: 0.6864
Round 42: 0.6941
Round 43: 0.6997
Round 44: 0.6816
Round 45: 0.7547
Round 46: 0.6778
Round 47: 0.9075
Round 48: 0.6744
Round 49: 0.7536
Round 50: 0.6735

Config:
dataset_names: {'high': 'high_TM', 'low': 'low_TM'}
filenames: {'high': 'data/high_matrices.h5', 'low': 'data/low_matrices.h5'}
normalize: False
standardize: False
log_normalize: True
batch_size: 128
learning_rate: 0.003
num_epochs: 50
model_type: edtmsr
num_clients: 10
num_rounds: 50
output_model_filename: model/edtmsr_model.pth
results_filename: results/edtmsr_fl_10clients_results.txt
