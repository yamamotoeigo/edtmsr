Num clients: 4
Training and evaluation took 2378.75 seconds.
Test Loss: 0.6138
Number of parameters in the model: 739777
Round losses:
Round 1: 1.4651
Round 2: 1.1857
Round 3: 0.8711
Round 4: 0.7780
Round 5: 0.7438
Round 6: 0.7251
Round 7: 0.7399
Round 8: 0.7013
Round 9: 0.6945
Round 10: 0.6899
Round 11: 0.6800
Round 12: 0.6716
Round 13: 0.6711
Round 14: 0.6640
Round 15: 0.6610
Round 16: 0.6563
Round 17: 0.6533
Round 18: 0.6515
Round 19: 0.6478
Round 20: 0.6493
Round 21: 0.6440
Round 22: 0.6420
Round 23: 0.6403
Round 24: 0.6391
Round 25: 0.6370
Round 26: 0.6359
Round 27: 0.6345
Round 28: 0.6333
Round 29: 0.6327
Round 30: 0.6293
Round 31: 0.6315
Round 32: 0.6269
Round 33: 0.6254
Round 34: 0.6245
Round 35: 0.6248
Round 36: 0.6254
Round 37: 0.6234
Round 38: 0.6223
Round 39: 0.6228
Round 40: 0.6219
Round 41: 0.6194
Round 42: 0.6197
Round 43: 0.6177
Round 44: 0.6220
Round 45: 0.6146
Round 46: 0.6156
Round 47: 0.6142
Round 48: 0.6129
Round 49: 0.6126
Round 50: 0.6138

Config:
dataset_names: {'high': 'high_TM', 'low': 'low_TM'}
filenames: {'high': 'data/high_matrices.h5', 'low': 'data/low_matrices.h5'}
normalize: False
standardize: False
log_normalize: True
batch_size: 128
learning_rate: 0.003
num_epochs: 50
model_type: edtmsr
num_clients: 4
num_rounds: 50
output_model_filename: model/edtmsr_model.pth
results_filename: results/edtmsr_fl_4clients_results.txt
